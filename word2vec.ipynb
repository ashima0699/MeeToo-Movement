{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AI_Project",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "BorX-RKxyefv"
      },
      "source": [
        "# importing necessary libraries\n",
        "import numpy as np \n",
        "import pandas as pd \n",
        "import seaborn as sns\n",
        "import os\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as mpatches\n",
        "import seaborn as sns\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.util import ngrams\n",
        "\n",
        "from wordcloud import WordCloud\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.decomposition import PCA, TruncatedSVD\n",
        "from sklearn.metrics import classification_report,confusion_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fCwe42HWV6Th",
        "outputId": "67ce66f2-5f21-4444-dbdc-05b335ec6d94"
      },
      "source": [
        "df = pd.read_csv('/content/Data/ResultFile_2.csv')\n",
        "myCopy = df.copy()\n",
        "df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8245, 12)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AA9X-uHbWFhr"
      },
      "source": [
        "df.drop(['tweet_id'],axis = 1, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mN8G3UMsWGo4"
      },
      "source": [
        "from nltk.stem.porter import *\n",
        "plt.style.use('seaborn')\n",
        "import plotly.express as px\n",
        "from plotly import graph_objs as go\n",
        "from collections import Counter\n",
        "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
        "from plotly.subplots import make_subplots\n",
        "import plotly.graph_objects as go"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QE93rIowWXoX",
        "outputId": "dfdb05e9-22e0-4c69-8f55-0aed9542aa72"
      },
      "source": [
        "for index, row in df.iterrows():\n",
        "    tweet = row.text\n",
        "    tweet = re.sub(r\"https\\S+\", \"\", tweet) #remove links\n",
        "    tweet = re.sub(r'#([^\\s]+)', r'\\1', tweet) #replace #word with word\n",
        "    \n",
        "    df['text'].iloc[index:index+1] = tweet"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py:670: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T6axHRH3WYn_",
        "outputId": "fe4fd2db-d559-48e9-e9ff-fed6a69836d7"
      },
      "source": [
        "#displaying tweets after above cleaning\n",
        "df['text'].head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    Domestic Violence Awareness Hasn’t Caught Up W...\n",
              "1                               Mother Nature’s MeToo \n",
              "2    It is 'high time' MeToo named and shamed men i...\n",
              "3    “There's this idea that persistence involves s...\n",
              "4                Meredith’s MeToo moment on TheOffice \n",
              "Name: text, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZyre_8PWrAw"
      },
      "source": [
        "# Helper function to remove unwanted patterns\n",
        "def remove_pattern(input_txt, pattern):\n",
        "    r = re.findall(pattern, input_txt)\n",
        "    for i in r:\n",
        "        input_txt = re.sub(i, '', input_txt)\n",
        "    return input_txt\n",
        "\n",
        "# Remove Twitter handles from the data \n",
        "df['text'] = np.vectorize(remove_pattern)(df['text'], \"@[\\w]*\")\n",
        "\n",
        "\n",
        "# Remove all words below 2 characters\n",
        "df['text'] = df['text'].apply(lambda x: ' '.join([w for w in x.split() if len(w)>2]))\n",
        "\n",
        "# Remove punctuations, numbers, and special characters\n",
        "df['text'] = df['text'].str.replace(\"[^a-zA-Z#]\", \" \")\n",
        "\n",
        "# Tokenize the tweets\n",
        "tokenized_tweet = df['text'].apply(lambda x: x.split())\n",
        "df['text_tokenised'] = tokenized_tweet\n",
        "for i in range(len(tokenized_tweet)):\n",
        "    tokenized_tweet[i] = ' '.join(tokenized_tweet[i])\n",
        "df['text'] = tokenized_tweet\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3bG37RTDWyIF",
        "outputId": "5a506cd2-dbd1-4c03-f931-0094b11da4a5"
      },
      "source": [
        "df['text_tokenised']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       [Domestic, Violence, Awareness, Hasn, t, Caugh...\n",
              "1                              [Mother, Nature, s, MeToo]\n",
              "2       [high, time, MeToo, named, and, shamed, men, m...\n",
              "3       [There, s, this, idea, that, persistence, invo...\n",
              "4                 [Meredith, s, MeToo, moment, TheOffice]\n",
              "                              ...                        \n",
              "8240      [Metoo, campaign, and, what, labour, laws, say]\n",
              "8241      [Metoo, campaign, and, what, labour, laws, say]\n",
              "8242    [Insightful, peace, Hala, Al, Karib, the, dang...\n",
              "8243    [Olivia, Munn, Opens, About, Predator, Scandal...\n",
              "8244    [Megan, Fox, feels, excluded, from, the, MeToo...\n",
              "Name: text_tokenised, Length: 8245, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d0H3H4duGe7Y"
      },
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "lemmatizer = WordNetLemmatizer()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DxruCORWGjQR"
      },
      "source": [
        "from nltk.corpus import wordnet\n",
        "def get_simple_pos(tag):\n",
        "    \n",
        "    if tag.startswith('J'):\n",
        "        return wordnet.ADJ\n",
        "    elif tag.startswith('V'):\n",
        "        return wordnet.VERB\n",
        "    elif tag.startswith('N'):\n",
        "        return wordnet.NOUN\n",
        "    elif tag.startswith('R'):\n",
        "        return wordnet.ADV\n",
        "    else:\n",
        "        return wordnet.NOUN"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nEqOnesYGjTC",
        "outputId": "787d9558-207b-4848-a409-2e1ed6c10709"
      },
      "source": [
        "from nltk import pos_tag\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "import string\n",
        "stops = set(stopwords.words('english'))\n",
        "\n",
        "stops"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'a',\n",
              " 'about',\n",
              " 'above',\n",
              " 'after',\n",
              " 'again',\n",
              " 'against',\n",
              " 'ain',\n",
              " 'all',\n",
              " 'am',\n",
              " 'an',\n",
              " 'and',\n",
              " 'any',\n",
              " 'are',\n",
              " 'aren',\n",
              " \"aren't\",\n",
              " 'as',\n",
              " 'at',\n",
              " 'be',\n",
              " 'because',\n",
              " 'been',\n",
              " 'before',\n",
              " 'being',\n",
              " 'below',\n",
              " 'between',\n",
              " 'both',\n",
              " 'but',\n",
              " 'by',\n",
              " 'can',\n",
              " 'couldn',\n",
              " \"couldn't\",\n",
              " 'd',\n",
              " 'did',\n",
              " 'didn',\n",
              " \"didn't\",\n",
              " 'do',\n",
              " 'does',\n",
              " 'doesn',\n",
              " \"doesn't\",\n",
              " 'doing',\n",
              " 'don',\n",
              " \"don't\",\n",
              " 'down',\n",
              " 'during',\n",
              " 'each',\n",
              " 'few',\n",
              " 'for',\n",
              " 'from',\n",
              " 'further',\n",
              " 'had',\n",
              " 'hadn',\n",
              " \"hadn't\",\n",
              " 'has',\n",
              " 'hasn',\n",
              " \"hasn't\",\n",
              " 'have',\n",
              " 'haven',\n",
              " \"haven't\",\n",
              " 'having',\n",
              " 'he',\n",
              " 'her',\n",
              " 'here',\n",
              " 'hers',\n",
              " 'herself',\n",
              " 'him',\n",
              " 'himself',\n",
              " 'his',\n",
              " 'how',\n",
              " 'i',\n",
              " 'if',\n",
              " 'in',\n",
              " 'into',\n",
              " 'is',\n",
              " 'isn',\n",
              " \"isn't\",\n",
              " 'it',\n",
              " \"it's\",\n",
              " 'its',\n",
              " 'itself',\n",
              " 'just',\n",
              " 'll',\n",
              " 'm',\n",
              " 'ma',\n",
              " 'me',\n",
              " 'mightn',\n",
              " \"mightn't\",\n",
              " 'more',\n",
              " 'most',\n",
              " 'mustn',\n",
              " \"mustn't\",\n",
              " 'my',\n",
              " 'myself',\n",
              " 'needn',\n",
              " \"needn't\",\n",
              " 'no',\n",
              " 'nor',\n",
              " 'not',\n",
              " 'now',\n",
              " 'o',\n",
              " 'of',\n",
              " 'off',\n",
              " 'on',\n",
              " 'once',\n",
              " 'only',\n",
              " 'or',\n",
              " 'other',\n",
              " 'our',\n",
              " 'ours',\n",
              " 'ourselves',\n",
              " 'out',\n",
              " 'over',\n",
              " 'own',\n",
              " 're',\n",
              " 's',\n",
              " 'same',\n",
              " 'shan',\n",
              " \"shan't\",\n",
              " 'she',\n",
              " \"she's\",\n",
              " 'should',\n",
              " \"should've\",\n",
              " 'shouldn',\n",
              " \"shouldn't\",\n",
              " 'so',\n",
              " 'some',\n",
              " 'such',\n",
              " 't',\n",
              " 'than',\n",
              " 'that',\n",
              " \"that'll\",\n",
              " 'the',\n",
              " 'their',\n",
              " 'theirs',\n",
              " 'them',\n",
              " 'themselves',\n",
              " 'then',\n",
              " 'there',\n",
              " 'these',\n",
              " 'they',\n",
              " 'this',\n",
              " 'those',\n",
              " 'through',\n",
              " 'to',\n",
              " 'too',\n",
              " 'under',\n",
              " 'until',\n",
              " 'up',\n",
              " 've',\n",
              " 'very',\n",
              " 'was',\n",
              " 'wasn',\n",
              " \"wasn't\",\n",
              " 'we',\n",
              " 'were',\n",
              " 'weren',\n",
              " \"weren't\",\n",
              " 'what',\n",
              " 'when',\n",
              " 'where',\n",
              " 'which',\n",
              " 'while',\n",
              " 'who',\n",
              " 'whom',\n",
              " 'why',\n",
              " 'will',\n",
              " 'with',\n",
              " 'won',\n",
              " \"won't\",\n",
              " 'wouldn',\n",
              " \"wouldn't\",\n",
              " 'y',\n",
              " 'you',\n",
              " \"you'd\",\n",
              " \"you'll\",\n",
              " \"you're\",\n",
              " \"you've\",\n",
              " 'your',\n",
              " 'yours',\n",
              " 'yourself',\n",
              " 'yourselves'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ov1pmT97GjWg"
      },
      "source": [
        "def clean_review(words):\n",
        "    output_words = []\n",
        "    for w in words:\n",
        "        if w.lower() not in stops:\n",
        "            pos = pos_tag([w])\n",
        "            clean_word = lemmatizer.lemmatize(w, pos = get_simple_pos(pos[0][1]))\n",
        "            output_words.append(clean_word.lower())\n",
        "    return output_words"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sr-17MaRGjZS",
        "outputId": "42d71124-9298-4114-b2f8-52c0f1f4dda4"
      },
      "source": [
        "import nltk\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('wordnet')\n",
        "documents = [clean_review(document) for document in df['text_tokenised']]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_sbLm-IXGjca",
        "outputId": "7f4574df-4dc5-4f39-9af3-3a6392b8aa82"
      },
      "source": [
        "documents[10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['nsw',\n",
              " 'police',\n",
              " 'officer',\n",
              " 'mitchell',\n",
              " 'willey',\n",
              " 'could',\n",
              " 'kick',\n",
              " 'force',\n",
              " 'admit',\n",
              " 'groped',\n",
              " 'woman',\n",
              " 'defqon',\n",
              " 'dan']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fLOnmgwnGjf4"
      },
      "source": [
        "documents_corrected = [\" \".join(x) for x in documents]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7IXqyyMFblSO"
      },
      "source": [
        "import gensim\n",
        "from gensim.models.word2vec import Word2Vec # the word2vec model gensim class\n",
        "LabeledSentence = gensim.models.doc2vec.LabeledSentence # we'll talk about this down below\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HpQdN13NW1Yh",
        "outputId": "eba6a660-1c1c-4909-f004-db99edd9a0b9"
      },
      "source": [
        "\n",
        "model_w2v = gensim.models.Word2Vec(\n",
        "            tokenized_tweet,\n",
        "            size=200, # desired no. of features/independent variables\n",
        "            window=5, # context window size\n",
        "            min_count=2, # Ignores all words with total frequency lower than 2.                                  \n",
        "            sg = 1, # 1 for skip-gram model\n",
        "            hs = 0,\n",
        "            negative = 10, # for negative sampling\n",
        "            workers= 32, # no.of cores\n",
        "            seed = 34) \n",
        "\n",
        "model_w2v.train(tokenized_tweet, total_examples= len(df['text']), epochs=20)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2753679, 12481260)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4DjEkpyZfaHo"
      },
      "source": [
        "def word_vector(tokens, size):\n",
        "    vec = np.zeros(size).reshape((1, size))\n",
        "    count = 0\n",
        "    for word in tokens:\n",
        "        try:\n",
        "            vec += model_w2v[word].reshape((1, size))\n",
        "            count += 1.\n",
        "        except KeyError:  # handling the case where the token is not in vocabulary\n",
        "            continue\n",
        "    if count != 0:\n",
        "        vec /= count\n",
        "    return vec"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_HRM68Sgfl5m",
        "outputId": "d45a24f3-6d9e-4994-924d-93c8460feefd"
      },
      "source": [
        "wordvec_arrays = np.zeros((len(tokenized_tweet), 200)) \n",
        "for i in range(len(tokenized_tweet)):\n",
        "    wordvec_arrays[i,:] = word_vector(tokenized_tweet[i], 200)\n",
        "wordvec_df = pd.DataFrame(wordvec_arrays)\n",
        "wordvec_df.shape\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: DeprecationWarning:\n",
            "\n",
            "Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8245, 200)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qDQF6ASSybR1",
        "outputId": "313c63b9-5b2b-4999-efd6-fa5f5c9fd576"
      },
      "source": [
        "wordvec_arrays[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-2.87751252e-02, -1.27613247e-01, -3.95850575e-02, -4.48977212e-02,\n",
              "        8.95629269e-02,  7.86018535e-02,  5.54860917e-02,  5.24534558e-02,\n",
              "       -1.51761148e-01, -4.49146405e-02, -1.12600913e-01,  2.36430398e-02,\n",
              "       -6.74020607e-02,  3.06507831e-02, -4.82180082e-02,  2.66598855e-02,\n",
              "       -4.56411819e-02,  9.25875319e-02,  1.01780203e-01, -4.15861461e-02,\n",
              "        2.80758128e-02,  7.35673078e-02, -1.35074248e-02, -7.85657527e-02,\n",
              "        1.92130656e-02,  5.41105454e-02, -7.71754864e-02,  2.86627109e-02,\n",
              "       -4.09461424e-02,  1.14541751e-02,  7.20762395e-02,  6.17711605e-02,\n",
              "        3.37541003e-02,  7.22711550e-03, -6.10903416e-02,  1.71220853e-01,\n",
              "        7.42829351e-02, -1.42567324e-01,  2.83183605e-03, -1.33439746e-01,\n",
              "        2.12685499e-02, -5.08787523e-02, -4.77514191e-02, -2.87909063e-02,\n",
              "       -6.43878638e-02, -1.20233184e-01, -5.86988906e-02, -1.58671903e-03,\n",
              "        2.76912043e-03, -3.91269456e-02,  4.92277628e-02,  5.81662488e-03,\n",
              "       -9.92105039e-02, -2.24124803e-04,  6.36541370e-02, -3.31888795e-02,\n",
              "        7.03507118e-02, -5.23729996e-03, -8.79882513e-04,  3.74001486e-02,\n",
              "        4.05760921e-02,  5.94398832e-03, -8.26942460e-03, -9.24465886e-02,\n",
              "        9.78634663e-02, -2.06853137e-03,  2.60889331e-02, -3.96546802e-03,\n",
              "        5.59347367e-02, -4.98628783e-02, -7.29149985e-02, -7.48213847e-02,\n",
              "        8.00610327e-02,  3.75729170e-02, -2.95192585e-02,  1.93038264e-02,\n",
              "        6.73827521e-02,  2.57396471e-02,  1.13770847e-02, -4.20607109e-02,\n",
              "       -6.34571562e-02, -5.76712441e-03,  1.11482691e-01, -1.10573123e-01,\n",
              "        3.99969013e-02,  2.62284080e-02,  1.34386595e-04,  5.84344509e-02,\n",
              "        2.36153000e-02, -2.65157741e-02,  8.92792593e-03, -7.69818258e-02,\n",
              "       -1.63815404e-03, -3.91169765e-02, -1.21631047e-02,  4.85778070e-02,\n",
              "       -6.88647551e-02, -3.08226198e-02, -2.27374819e-03,  3.90138996e-02,\n",
              "       -1.76219627e-01, -1.03540929e-01,  6.58934256e-02, -1.41331703e-01,\n",
              "       -4.85281444e-02,  1.89715889e-02,  1.79864106e-02,  2.52682309e-02,\n",
              "        5.93471918e-02, -1.31962505e-02,  5.35025077e-02,  7.25639004e-02,\n",
              "       -8.21075941e-02, -2.98775021e-02,  2.01356306e-02, -1.35247343e-02,\n",
              "        1.91820872e-02, -4.10390126e-02,  7.47275830e-02,  1.46356838e-02,\n",
              "       -8.00008658e-03, -1.88325935e-02,  6.03209032e-03,  2.55996303e-02,\n",
              "       -3.68315498e-02, -2.74601667e-02,  4.27213226e-02, -1.67817441e-02,\n",
              "       -6.65467260e-02,  2.14041990e-02, -6.29652521e-02, -9.30643279e-02,\n",
              "        7.17695421e-02, -3.11488633e-03,  1.14927260e-01, -3.71023026e-02,\n",
              "       -4.55303215e-02,  7.50500843e-03,  3.59640292e-02,  4.38640755e-02,\n",
              "       -1.23407893e-01,  3.35970457e-02, -7.22789776e-02,  8.15974515e-02,\n",
              "       -7.98699290e-03, -6.58868965e-02,  5.15971999e-02, -1.26289432e-01,\n",
              "       -1.42047186e-01, -1.27330485e-01, -5.17986883e-02,  6.11819306e-02,\n",
              "        6.29429986e-02,  4.86292193e-02,  1.22809075e-02,  3.36203580e-02,\n",
              "        5.34384409e-02, -1.08949966e-01,  9.70825034e-03,  9.71150174e-02,\n",
              "        1.30867807e-02,  5.39094268e-02,  1.13839516e-01,  4.54352020e-02,\n",
              "        1.11121505e-02, -2.99226677e-02,  8.70375616e-02, -2.84091776e-03,\n",
              "        1.16098217e-01,  9.65500028e-02, -1.50790767e-01, -1.65949021e-02,\n",
              "        5.54774145e-02,  8.76226392e-02,  1.31868810e-03,  2.70349911e-02,\n",
              "        9.80637364e-02,  5.21527592e-02,  3.17201233e-02,  1.04109282e-01,\n",
              "        1.73618737e-02, -7.13464345e-02, -2.07230395e-02, -7.74421698e-02,\n",
              "        8.56205994e-03,  5.64561477e-02,  4.87810860e-02,  2.81106831e-03,\n",
              "       -3.54173316e-02,  4.23958842e-02,  9.72885623e-02, -2.16444971e-01,\n",
              "        9.37268362e-02, -6.89839500e-02,  1.80654730e-04, -4.45466078e-02,\n",
              "       -8.09651442e-02, -2.90843391e-02, -6.50026706e-02,  4.88450478e-02])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RVbRE4AUFEEQ"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4Nv1sf9ItQc"
      },
      "source": [
        "from sklearn.model_selection import train_test_split  \n",
        "## splitting for relevance\n",
        "X_train_relevance, X_test_relevance, y_train_relevance, y_test_relevance = train_test_split(wordvec_df,df['relevance'] , test_size=0.3, random_state=0)\n",
        "\n",
        "## splitting for directed_hate\n",
        "X_train_dh, X_test_dh, y_train_dh, y_test_dh = train_test_split(wordvec_df,df['directed_hate'] , test_size=0.3, random_state=0)\n",
        "\n",
        "## splitting for generalised_hate\n",
        "X_train_gh, X_test_gh, y_train_gh, y_test_gh = train_test_split(wordvec_df,df['generalised_hate'] , test_size=0.3, random_state=0)\n",
        "\n",
        "## splitting for sarcasm\n",
        "X_train_sarcasm, X_test_sarcasm, y_train_sarcasm, y_test_sarcasm = train_test_split(wordvec_df,df['sarcasm'] , test_size=0.3, random_state=0)\n",
        "\n",
        "## splitting for allegation\n",
        "X_train_allegation, X_test_allegation, y_train_allegation, y_test_allegation = train_test_split(wordvec_df,df['allegation'] , test_size=0.3, random_state=0)\n",
        "\n",
        "## splitting for justification\n",
        "X_train_justification, X_test_justification, y_train_justification, y_test_justification = train_test_split(wordvec_df,df['justification'] , test_size=0.3, random_state=0)\n",
        "\n",
        "## splitting for refutation\n",
        "X_train_refutation, X_test_refutation, y_train_refutation, y_test_refutation = train_test_split(wordvec_df,df['refutation'] , test_size=0.3, random_state=0)\n",
        "\n",
        "## splitting for Support\n",
        "X_train_Support, X_test_Support, y_train_Support, y_test_Support = train_test_split(wordvec_df,df['Favour'] , test_size=0.3, random_state=0)\n",
        "\n",
        "## splitting for oppose\n",
        "X_train_oppose, X_test_oppose, y_train_oppose, y_test_oppose = train_test_split(wordvec_df,df['oppose'] , test_size=0.3, random_state=0)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qFku5c-dIuSf",
        "outputId": "430a295c-5080-4d2e-a3f1-275612bd19c3"
      },
      "source": [
        "##training for relevance\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "text_classifier = RandomForestClassifier(n_estimators=100, random_state=0)  \n",
        "text_classifier.fit(X_train_relevance, y_train_relevance)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=None, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
              "                       n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
              "                       warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dtF7-EtHIufs"
      },
      "source": [
        "predictions = text_classifier.predict(X_test_relevance)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qkDAvef6IujQ",
        "outputId": "96d56ab4-169c-4b13-a132-e09620cd31a4"
      },
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "\n",
        "print(confusion_matrix(y_test_relevance,predictions))  \n",
        "print(classification_report(y_test_relevance,predictions))  \n",
        "print(accuracy_score(y_test_relevance, predictions))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[  38  599]\n",
            " [  79 1758]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.32      0.06      0.10       637\n",
            "           1       0.75      0.96      0.84      1837\n",
            "\n",
            "    accuracy                           0.73      2474\n",
            "   macro avg       0.54      0.51      0.47      2474\n",
            "weighted avg       0.64      0.73      0.65      2474\n",
            "\n",
            "0.7259498787388844\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Le8r4x7nIumo",
        "outputId": "cc0d9ee0-c392-4116-d192-5de0b7968d9d"
      },
      "source": [
        "##training for directed_hate\n",
        "text_classifier.fit(X_train_dh, y_train_dh)\n",
        "predictions_dh = text_classifier.predict(X_test_dh)\n",
        "print(confusion_matrix(y_test_dh,predictions_dh))  \n",
        "print(classification_report(y_test_dh,predictions_dh))  \n",
        "print(accuracy_score(y_test_dh, predictions_dh))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[2356   12]\n",
            " [ 105    1]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.99      0.98      2368\n",
            "           1       0.08      0.01      0.02       106\n",
            "\n",
            "    accuracy                           0.95      2474\n",
            "   macro avg       0.52      0.50      0.50      2474\n",
            "weighted avg       0.92      0.95      0.93      2474\n",
            "\n",
            "0.9527081649151172\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KDYudIHlIuqB",
        "outputId": "b43af175-91a4-4c70-a66c-b94e50cf0e1d"
      },
      "source": [
        "##training for generalised_hate\n",
        "text_classifier.fit(X_train_gh, y_train_gh)\n",
        "predictions_gh = text_classifier.predict(X_test_gh)\n",
        "print(confusion_matrix(y_test_gh,predictions_gh))  \n",
        "print(classification_report(y_test_gh,predictions_gh))  \n",
        "print(accuracy_score(y_test_gh, predictions_gh))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[2397   12]\n",
            " [  64    1]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      1.00      0.98      2409\n",
            "           1       0.08      0.02      0.03        65\n",
            "\n",
            "    accuracy                           0.97      2474\n",
            "   macro avg       0.53      0.51      0.51      2474\n",
            "weighted avg       0.95      0.97      0.96      2474\n",
            "\n",
            "0.9692805173807599\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BrXTeFUiIutJ",
        "outputId": "8650a339-c27f-475d-ba59-178bb59917c2"
      },
      "source": [
        "##training for sarcasm\n",
        "text_classifier.fit(X_train_sarcasm, y_train_sarcasm)\n",
        "predictions_sarcasm = text_classifier.predict(X_test_sarcasm)\n",
        "print(confusion_matrix(y_test_sarcasm,predictions_sarcasm))  \n",
        "print(classification_report(y_test_sarcasm,predictions_sarcasm))  \n",
        "print(accuracy_score(y_test_sarcasm, predictions_sarcasm))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[2420    5]\n",
            " [  48    1]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99      2425\n",
            "           1       0.17      0.02      0.04        49\n",
            "\n",
            "    accuracy                           0.98      2474\n",
            "   macro avg       0.57      0.51      0.51      2474\n",
            "weighted avg       0.96      0.98      0.97      2474\n",
            "\n",
            "0.9785772029102667\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bNgbwRddIuwY",
        "outputId": "ed7cad63-dcaa-443d-b7e5-39984734560f"
      },
      "source": [
        "##training for allegation\n",
        "text_classifier.fit(X_train_allegation, y_train_allegation)\n",
        "predictions_allegation = text_classifier.predict(X_test_allegation)\n",
        "print(confusion_matrix(y_test_allegation,predictions_allegation))  \n",
        "print(classification_report(y_test_allegation,predictions_allegation))  \n",
        "print(accuracy_score(y_test_allegation, predictions_allegation))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[2310   19]\n",
            " [ 142    3]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.99      0.97      2329\n",
            "           1       0.14      0.02      0.04       145\n",
            "\n",
            "    accuracy                           0.93      2474\n",
            "   macro avg       0.54      0.51      0.50      2474\n",
            "weighted avg       0.89      0.93      0.91      2474\n",
            "\n",
            "0.9349232012934519\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DYw_9VvRIuzr",
        "outputId": "01d18b92-2766-4478-ad50-e94e05e0c195"
      },
      "source": [
        "##training for justification\n",
        "text_classifier.fit(X_train_justification, y_train_justification)\n",
        "predictions_justification= text_classifier.predict(X_test_justification)\n",
        "print(confusion_matrix(y_test_justification,predictions_justification))  \n",
        "print(classification_report(y_test_justification,predictions_justification))  \n",
        "print(accuracy_score(y_test_justification, predictions_justification))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[2390    8]\n",
            " [  75    1]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      1.00      0.98      2398\n",
            "           1       0.11      0.01      0.02        76\n",
            "\n",
            "    accuracy                           0.97      2474\n",
            "   macro avg       0.54      0.50      0.50      2474\n",
            "weighted avg       0.94      0.97      0.95      2474\n",
            "\n",
            "0.9664510913500404\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-2IQ57IOIu25",
        "outputId": "3090486b-9a34-4159-d1e2-be733c8805be"
      },
      "source": [
        "##training for refutation\n",
        "text_classifier.fit(X_train_refutation, y_train_refutation)\n",
        "predictions_refutation= text_classifier.predict(X_test_refutation)\n",
        "print(confusion_matrix(y_test_refutation,predictions_refutation))  \n",
        "print(classification_report(y_test_refutation,predictions_refutation))  \n",
        "print(accuracy_score(y_test_refutation, predictions_refutation))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[2409    2]\n",
            " [  62    1]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      1.00      0.99      2411\n",
            "           1       0.33      0.02      0.03        63\n",
            "\n",
            "    accuracy                           0.97      2474\n",
            "   macro avg       0.65      0.51      0.51      2474\n",
            "weighted avg       0.96      0.97      0.96      2474\n",
            "\n",
            "0.9741309620048505\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1zrXL0TLKIil",
        "outputId": "0c3891bb-d9a3-4910-8718-2bbee7a49488"
      },
      "source": [
        "##training for Support\n",
        "text_classifier.fit(X_train_Support, y_train_Support)\n",
        "predictions_Support= text_classifier.predict(X_test_Support)\n",
        "print(confusion_matrix(y_test_Support,predictions_Support))  \n",
        "print(classification_report(y_test_Support,predictions_Support))  \n",
        "print(accuracy_score(y_test_Support, predictions_Support))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1567   90]\n",
            " [ 782   35]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.95      0.78      1657\n",
            "           1       0.28      0.04      0.07       817\n",
            "\n",
            "    accuracy                           0.65      2474\n",
            "   macro avg       0.47      0.49      0.43      2474\n",
            "weighted avg       0.54      0.65      0.55      2474\n",
            "\n",
            "0.6475343573160873\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8wX7vpkGKIll",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c66a35b1-01c5-4bca-83ff-2caaaa296ead"
      },
      "source": [
        "##training for oppose\n",
        "text_classifier.fit(X_train_oppose, y_train_oppose)\n",
        "predictions_oppose= text_classifier.predict(X_test_oppose)\n",
        "print(confusion_matrix(y_test_oppose,predictions_oppose))  \n",
        "print(classification_report(y_test_oppose,predictions_oppose))  \n",
        "print(accuracy_score(y_test_oppose, predictions_oppose))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[2274   17]\n",
            " [ 180    3]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.99      0.96      2291\n",
            "           1       0.15      0.02      0.03       183\n",
            "\n",
            "    accuracy                           0.92      2474\n",
            "   macro avg       0.54      0.50      0.49      2474\n",
            "weighted avg       0.87      0.92      0.89      2474\n",
            "\n",
            "0.9203718674211803\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nb5Nq7CKKIof",
        "outputId": "ce716d8d-e00b-491f-b153-e044597be5ed"
      },
      "source": [
        "##training for relevance\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import Normalizer\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "GB_model = GaussianNB()\n",
        "\n",
        "GB_model.fit(X_train_relevance, y_train_relevance)\n",
        "y_predict_relevance= GB_model.predict(X_test_relevance)\n",
        "print(accuracy_score(y_test_relevance, y_predict_relevance))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.30072756669361356\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_BTm-6YlKIrw",
        "outputId": "df3d3944-ecdb-4d07-b068-c0a59bd33ec8"
      },
      "source": [
        "##training for directed_hate\n",
        "GB_model.fit(X_train_dh, y_train_dh)\n",
        "y_predict_dh= GB_model.predict(X_test_dh)\n",
        "print(accuracy_score(y_test_dh, y_predict_dh))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6548100242522231\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mK5Wffl0KIu6",
        "outputId": "8ef1746e-edf7-4c5b-b337-f4fd0ce725bd"
      },
      "source": [
        "##training for generalised_hate\n",
        "GB_model.fit(X_train_gh, y_train_gh)\n",
        "y_predict_gh= GB_model.predict(X_test_gh)\n",
        "print(accuracy_score(y_test_gh, y_predict_gh))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9256265157639451\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0RsuhlDeT4ZE",
        "outputId": "f5873be9-478f-4e33-f37f-7e97602f0e41"
      },
      "source": [
        "##training for sarcasm\n",
        "GB_model.fit(X_train_sarcasm, y_train_sarcasm)\n",
        "y_predict_sarcasm= GB_model.predict(X_test_sarcasm)\n",
        "print(accuracy_score(y_test_sarcasm, y_predict_sarcasm))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.936944219886823\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ht6HdlKDKIzX",
        "outputId": "9739b445-622d-41cd-b59a-812a3901bf93"
      },
      "source": [
        "##training for allegation\n",
        "GB_model.fit(X_train_allegation, y_train_allegation)\n",
        "y_predict_allegation= GB_model.predict(X_test_allegation)\n",
        "print(accuracy_score(y_test_allegation, y_predict_allegation))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9106709781729992\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tc0kVwVVKI19",
        "outputId": "4be2a90a-644e-4f93-b641-46c1710281ae"
      },
      "source": [
        "##training for justification\n",
        "GB_model.fit(X_train_justification, y_train_justification)\n",
        "y_predict_justification= GB_model.predict(X_test_justification)\n",
        "print(accuracy_score(y_test_justification, y_predict_justification))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.896928051738076\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A0CTDVJbKI44",
        "outputId": "437021c8-b90e-461d-850c-52f4a9f5c360"
      },
      "source": [
        "##training for refutation\n",
        "GB_model.fit(X_train_refutation, y_train_refutation)\n",
        "y_predict_refutation= GB_model.predict(X_test_refutation)\n",
        "print(accuracy_score(y_test_refutation, y_predict_refutation))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8779304769603881\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ApWSx-7OKI7f",
        "outputId": "90c068df-8c4f-4883-e884-0571bce968e5"
      },
      "source": [
        "##training for Support\n",
        "GB_model.fit(X_train_Support, y_train_Support)\n",
        "y_predict_Support= GB_model.predict(X_test_Support)\n",
        "print(accuracy_score(y_test_Support, y_predict_Support))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.5804365400161682\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VjLN3ISjKI_E",
        "outputId": "e451d31b-cabf-4315-dc9f-475fceb82b56"
      },
      "source": [
        "##training for oppose\n",
        "GB_model.fit(X_train_oppose, y_train_oppose)\n",
        "y_predict_oppose= GB_model.predict(X_test_oppose)\n",
        "print(accuracy_score(y_test_oppose, y_predict_oppose))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8423605497170574\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XKcO_f_zKJCH",
        "outputId": "d84e59b0-9a57-4113-edaa-367e8ba7921f"
      },
      "source": [
        "##training for relevance\n",
        "from sklearn import svm\n",
        "rbf = svm.SVC(kernel='rbf', gamma=0.5, C=0.1).fit(X_train_relevance, y_train_relevance)\n",
        "rbf_pred_relevance = rbf.predict(X_test_relevance)\n",
        "rbf_accuracy = accuracy_score(y_test_relevance, rbf_pred_relevance)\n",
        "print(rbf_accuracy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7425222312045271\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6YEUGOYRKJFo",
        "outputId": "b3af2795-37d6-442e-cac0-9023573e2c2b"
      },
      "source": [
        "##training for directed_hate\n",
        "rbf = svm.SVC(kernel='rbf', gamma=0.5, C=0.1).fit(X_train_dh, y_train_dh)\n",
        "rbf_pred_dh = rbf.predict(X_test_dh)\n",
        "rbf_accuracy = accuracy_score(y_test_dh, rbf_pred_dh)\n",
        "print(rbf_accuracy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9571544058205336\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJk86qXcKJI8",
        "outputId": "2d095051-0dfa-41c6-9518-1e1deae71396"
      },
      "source": [
        "##training for generalised_hate\n",
        "rbf = svm.SVC(kernel='rbf', gamma=0.5, C=0.1).fit(X_train_gh, y_train_gh)\n",
        "rbf_pred_gh = rbf.predict(X_test_gh)\n",
        "rbf_accuracy = accuracy_score(y_test_gh, rbf_pred_gh)\n",
        "print(rbf_accuracy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9737267582861763\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oy5aRpWUKJMD",
        "outputId": "f930eeeb-8166-419c-f6cf-78ff360a35a0"
      },
      "source": [
        "##training for sarcasm\n",
        "rbf = svm.SVC(kernel='rbf', gamma=0.5, C=0.1).fit(X_train_sarcasm, y_train_sarcasm)\n",
        "rbf_pred_sarcasm = rbf.predict(X_test_sarcasm)\n",
        "rbf_accuracy = accuracy_score(y_test_sarcasm, rbf_pred_sarcasm)\n",
        "print(rbf_accuracy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9801940177849636\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PH8ru1MKKJPe",
        "outputId": "1c688e79-3643-4e63-cb61-b6786f44ed01"
      },
      "source": [
        "##training for allegation\n",
        "rbf = svm.SVC(kernel='rbf', gamma=0.5, C=0.1).fit(X_train_allegation, y_train_allegation)\n",
        "rbf_pred_allegation = rbf.predict(X_test_allegation)\n",
        "rbf_accuracy = accuracy_score(y_test_allegation, rbf_pred_allegation)\n",
        "print(rbf_accuracy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9413904607922393\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o1i8CKouSOdP",
        "outputId": "65be819b-0026-4c80-f6d9-9762593f4fcc"
      },
      "source": [
        "##training for justification\n",
        "rbf = svm.SVC(kernel='rbf', gamma=0.5, C=0.1).fit(X_train_justification, y_train_justification)\n",
        "rbf_pred_justification = rbf.predict(X_test_justification)\n",
        "rbf_accuracy = accuracy_score(y_test_justification, rbf_pred_justification)\n",
        "print(rbf_accuracy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9692805173807599\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6kur7FekSOzj",
        "outputId": "1024896d-7c1d-47e8-d0de-5f9124c5ace9"
      },
      "source": [
        "##training for refutation\n",
        "rbf = svm.SVC(kernel='rbf', gamma=0.5, C=0.1).fit(X_train_refutation, y_train_refutation)\n",
        "rbf_pred_refutation = rbf.predict(X_test_refutation)\n",
        "rbf_accuracy = accuracy_score(y_test_refutation, rbf_pred_refutation)\n",
        "print(rbf_accuracy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9745351657235246\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "89NAEMScSPZs",
        "outputId": "63fd3ad5-0ab8-4308-d8e0-ed9e405f89f6"
      },
      "source": [
        "##training for Support\n",
        "rbf = svm.SVC(kernel='rbf', gamma=0.5, C=0.1).fit(X_train_Support, y_train_Support)\n",
        "rbf_pred_Support = rbf.predict(X_test_Support)\n",
        "rbf_accuracy = accuracy_score(y_test_Support, rbf_pred_Support)\n",
        "print(rbf_accuracy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6697655618431689\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61HcnKf0SV_G",
        "outputId": "097b5c67-7411-40d4-97f3-26423c8b7e9d"
      },
      "source": [
        "##training for Oppose\n",
        "rbf = svm.SVC(kernel='rbf', gamma=0.5, C=0.1).fit(X_train_oppose, y_train_oppose)\n",
        "rbf_pred_oppose = rbf.predict(X_test_oppose)\n",
        "rbf_accuracy = accuracy_score(y_test_oppose, rbf_pred_oppose)\n",
        "print(rbf_accuracy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9260307194826193\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}